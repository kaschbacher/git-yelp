{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "from gensim import corpora, models, similarities, utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyLDAvis.gensim\n",
    "import pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.ldamodel.LdaModel"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f = file('lda.pkl', 'rb')\n",
    "# loaded_obj = pickle.load(f)\n",
    "lda = pickle.load(open('lda.p','rb'))\n",
    "# f.close()\n",
    "type(lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'0.021*dr + 0.006*care + 0.005*one + 0.005*doctor + 0.004*see + 0.004*time + 0.004*get + 0.004*would + 0.003*like + 0.003*years',\n",
       " u\"0.026*dr + 0.005*like + 0.005*great + 0.005*i've + 0.005*office + 0.004*he's + 0.004*would + 0.004*get + 0.004*doctor + 0.004*see\",\n",
       " u'0.030*dr + 0.007*time + 0.006*great + 0.006*really + 0.005*staff + 0.005*would + 0.005*see + 0.005*office + 0.005*surgery + 0.005*doctor',\n",
       " u'0.025*dr + 0.006*would + 0.006*time + 0.005*back + 0.004*like + 0.004*surgery + 0.004*could + 0.004*get + 0.004*recommend + 0.004*staff',\n",
       " u'0.018*dr + 0.006*would + 0.005*like + 0.005*time + 0.004*surgery + 0.004*medical + 0.004*get + 0.004*office + 0.004*back + 0.004*one',\n",
       " u'0.018*dr + 0.011*doctor + 0.008*care + 0.006*time + 0.006*really + 0.005*great + 0.005*see + 0.005*like + 0.005*medical + 0.005*office',\n",
       " u'0.020*dr + 0.006*one + 0.005*like + 0.005*medical + 0.005*doctor + 0.005*get + 0.004*feel + 0.004*time + 0.004*great + 0.004*office',\n",
       " u'0.013*dr + 0.009*get + 0.008*office + 0.007*would + 0.007*doctor + 0.006*time + 0.006*call + 0.005*called + 0.005*one + 0.005*see',\n",
       " u\"0.026*dr + 0.005*i've + 0.005*years + 0.005*surgery + 0.005*staff + 0.004*time + 0.004*office + 0.004*look + 0.004*like + 0.004*really\",\n",
       " u'0.019*dr + 0.007*doctor + 0.006*one + 0.005*like + 0.005*would + 0.005*get + 0.005*surgery + 0.004*office + 0.004*time + 0.004*see']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a new corpus & apply LDA model to the new corpus\n",
    "# https://radimrehurek.com/gensim/models/ldamodel.html#id2\n",
    "# https://radimrehurek.com/gensim/wiki.html#latent-dirichlet-allocation\n",
    "\n",
    "new_document = [u\"\"\"We love Tamalpais Pediatrics and our children's doctor, John Lee. Like other reviewers have found, with their doctors, \n",
    "           Dr. Lee is patient, listens and addresses concerns we have about our childrens health.  I don't know if all pediatricians will come to the hospital to meet the new baby, but Dr. Lee has come to see both our daughters after they were born...\n",
    "           We've seen Dr. Branco when Dr. Lee was unavailable and were relieved to see he and Dr. Lee are very similar in bedside manners.  \n",
    "        Crystal Cox, the PA, is also a dream.  Shes warm and very easygoing with our young children.  I've no problems having her see the kids when one of the MD s are not available.\n",
    "        I'm sorry to see Deana S. did not have a good experience with the receptionist, but I have to say that I've never had any problems with any of the staff.  They are all professional and very caring with the children.  \n",
    "        5 Stars!  Thumbs up!\"\"\"]\n",
    "# QUICK FORMAT: remove extra spaces and new lines\n",
    "new_document = [\" \".join(element.replace(\"\\n\",\"\").split()) for element in new_doc]\n",
    "#print(new_document)#type list, shape: (1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def canonicalize(word):    \n",
    "    bads = ['dr.',\"n't\",\"'ve\",\"'re\",'wo',\"'m\"]\n",
    "    goods = ['dr','not','have','are','will','am']\n",
    "\n",
    "    try:\n",
    "        idx = bads.index(word)\n",
    "        word=goods[idx]\n",
    "    except ValueError as e:\n",
    "        word=word\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defines the pattern for money and times - used by nltk tokenizer\n",
    "def get_pat_for_tokenizer():\n",
    "    from nltk.tokenize import regexp_tokenize\n",
    "    \"\"\"money and time patterns formatted to fit in nltk RegexpTokenizer object, debugged with s2 below\"\"\"\n",
    "    #s2 = 'it took until 12:30 am to get an appointment and I spent $3.50'\n",
    "    \n",
    "    pat = '\\w+|\\$[\\d\\.]+|\\S+'\n",
    "    pat2 = '\\d+\\:[\\d]+\\s?(pm|am)|\\S+'\n",
    "\n",
    "    final_pattern = '('+pat2+')' +'|'+ '('+pat+')'#must be one string argument... | is OR\n",
    "    return final_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NLTK code\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "tokenizer = RegexpTokenizer(get_pat_for_tokenizer())#time & money\n",
    "\n",
    "# document obj passed to tokenizer must be type str\n",
    "texts = [canonicalize(word) for word in tokenizer.tokenize(str(new_document).lower()) \n",
    "         if word not in stopwords.words()]\n",
    "texts = [texts]#BOW dictionary requires texts obj be converted from type str to list\n",
    "#print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(69 unique tokens: [u'dream.', u'love', u'addresses', u\"don't\", u'doctor,']...)\n"
     ]
    }
   ],
   "source": [
    "# Store Dictionary\n",
    "new_dictionary = corpora.Dictionary(texts)# create dictionary object from cleaned texts (texts type list obj)\n",
    "new_dictionary.save('tamalpais_pediatrics.dict') # store the dictionary, for future reference\n",
    "print(new_dictionary)\n",
    "#print(new_dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0\n",
      "5   0.532051\n",
      "8   0.458309\n",
      "6   0.001205\n",
      "3   0.001205\n",
      "10  0.001205\n",
      "2   0.001205\n",
      "7   0.001205\n",
      "9   0.001205\n",
      "4   0.001205\n",
      "1   0.001205\n"
     ]
    }
   ],
   "source": [
    "# FORM new Bag-of-words corpus (count vectors)\n",
    "# A trained LDA model can used be to transform new, unseen documents (formatted as BOW)\n",
    "\n",
    "new_corpus = [new_dictionary.doc2bow(text) for text in texts]#both text and texts are type list\n",
    "\n",
    "# Obtain LDA topic distributions for new BOW corpus:\n",
    "#\n",
    "# get topic probability distribution for a new review\n",
    "# object: <gensim.interfaces.TransformedCorpus object\n",
    "new_doc_lda = lda[new_corpus]\n",
    "#new_doc_lda.print_topics()#doesn't work\n",
    "#print(new_doc_lda)#This just prints the  at 0x10d3ccf10>\n",
    "#print(lda.top_topics(corpus, num_words=5)[:][0])\n",
    "#lda.top_topics(corpus, num_words=5)#shape (10,2) for num_words=5\n",
    "#lda.print_topics(10)\n",
    "\n",
    "# Obtain GAMMAS MATRIX:  topics by documents\n",
    "# gammas =  (parameters controlling the topic weights) for each document\n",
    "# Is normalization needed?\n",
    "# throws away sstats, the second part of the returned tuple\n",
    "gammas,_ = lda.inference(new_corpus)# first element is gammas matrix: \n",
    "norm_gammas = gammas/np.sum(gammas,axis=1)\n",
    "#print(gammas)\n",
    "#print(norm_gammas)\n",
    "\n",
    "# PUT GAMMAS IN DATAFRAME, SORTED BY TOPIC IMPORTANCE\n",
    "# Set row indices to match LDA topic numbers instead of being 0-indexed\n",
    "df = pd.DataFrame(norm_gammas.T, index=np.arange(1,11))\n",
    "#print(df)\n",
    "print(df.sort(0,axis=0,ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# KEY QUESTIONS/To DO\n",
    "# *** Still confused about exactly what to graph\n",
    "# *** How do I get an example review that is highly \"representative of a given topic?\"\n",
    "# I still don't know the best way to reduce the topic dimensonality space\n",
    "# Work on resume\n",
    "# Revise the Yelp API program and split into two programs - 1) get businesses, 2) get reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# row = [[d[1] for d in doc] for doc in corpus_lsi]\n",
    "# df = pd.DataFrame(row).sort(0,axis=0,ascending=False)#0 sorts on the first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dictionary' object has no attribute 'id2word'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-9d493308131a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Visualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvis_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_corpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_dictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvis_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dictionary' object has no attribute 'id2word'"
     ]
    }
   ],
   "source": [
    "# Visualization\n",
    "\n",
    "vis_data = pyLDAvis.gensim.prepare(lda, new_corpus, new_dictionary)\n",
    "pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "from gensim import corpora, models, similarities, utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.ldamodel.LdaModel"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f = file('lda.pkl', 'rb')\n",
    "# loaded_obj = pickle.load(f)\n",
    "lda = pickle.load(open('lda.p','rb'))\n",
    "# f.close()\n",
    "type(lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'0.021*dr + 0.006*care + 0.005*one + 0.005*doctor + 0.004*see + 0.004*time + 0.004*get + 0.004*would + 0.003*like + 0.003*years',\n",
       " u\"0.026*dr + 0.005*like + 0.005*great + 0.005*i've + 0.005*office + 0.004*he's + 0.004*would + 0.004*get + 0.004*doctor + 0.004*see\",\n",
       " u'0.030*dr + 0.007*time + 0.006*great + 0.006*really + 0.005*staff + 0.005*would + 0.005*see + 0.005*office + 0.005*surgery + 0.005*doctor',\n",
       " u'0.025*dr + 0.006*would + 0.006*time + 0.005*back + 0.004*like + 0.004*surgery + 0.004*could + 0.004*get + 0.004*recommend + 0.004*staff',\n",
       " u'0.018*dr + 0.006*would + 0.005*like + 0.005*time + 0.004*surgery + 0.004*medical + 0.004*get + 0.004*office + 0.004*back + 0.004*one',\n",
       " u'0.018*dr + 0.011*doctor + 0.008*care + 0.006*time + 0.006*really + 0.005*great + 0.005*see + 0.005*like + 0.005*medical + 0.005*office',\n",
       " u'0.020*dr + 0.006*one + 0.005*like + 0.005*medical + 0.005*doctor + 0.005*get + 0.004*feel + 0.004*time + 0.004*great + 0.004*office',\n",
       " u'0.013*dr + 0.009*get + 0.008*office + 0.007*would + 0.007*doctor + 0.006*time + 0.006*call + 0.005*called + 0.005*one + 0.005*see',\n",
       " u\"0.026*dr + 0.005*i've + 0.005*years + 0.005*surgery + 0.005*staff + 0.004*time + 0.004*office + 0.004*look + 0.004*like + 0.004*really\",\n",
       " u'0.019*dr + 0.007*doctor + 0.006*one + 0.005*like + 0.005*would + 0.005*get + 0.005*surgery + 0.004*office + 0.004*time + 0.004*see']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "# Create a new corpus & apply LDA model to the new corpus\n",
    "# https://radimrehurek.com/gensim/models/ldamodel.html#id2\n",
    "# https://radimrehurek.com/gensim/wiki.html#latent-dirichlet-allocation\n",
    "\n",
    "new_doc = [u\"\"\"We love Tamalpais Pediatrics and our children's doctor, John Lee. Like other reviewers have found, with their doctors, \n",
    "           Dr. Lee is patient, listens and addresses concerns we have about our childrens health.  I don't know if all pediatricians will come to the hospital to meet the new baby, but Dr. Lee has come to see both our daughters after they were born...\n",
    "           We've seen Dr. Branco when Dr. Lee was unavailable and were relieved to see he and Dr. Lee are very similar in bedside manners.  \n",
    "        Crystal Cox, the PA, is also a dream.  Shes warm and very easygoing with our young children.  I've no problems having her see the kids when one of the MD s are not available.\n",
    "        I'm sorry to see Deana S. did not have a good experience with the receptionist, but I have to say that I've never had any problems with any of the staff.  They are all professional and very caring with the children.  \n",
    "        5 Stars!  Thumbs up!\"\"\"]\n",
    "# QUICK FORMAT: remove extra spaces and new lines\n",
    "new_doc = [\" \".join(element.replace(\"\\n\",\"\").split()) for element in new_doc]\n",
    "print(np.shape(new_doc))\n",
    "#print(new_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NLTK code\n",
    "# remove common words and tokenize\n",
    "common_words2 = 'for a of the and to in is \\'s by on the to , . `` ? _ - / \"\\\"'\n",
    "stoplist2 = set(common_words2.split())\n",
    "\n",
    "#texts: A list of lists; text: list of tokenized words from 1 doc/review\n",
    "texts2 = [[word2 for word2 in nltk.word_tokenize(doc.lower()) if word2 not in stoplist2]\n",
    "        for doc in new_docs]#review in reviews \n",
    "#print(texts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-885b9cc23310>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#texts: A list of lists; text: list of tokenized words from 1 doc/review\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m texts2 = [[word2 for word2 in nltk.word_tokenize(doc.lower()) if word2 not in stoplist2]\n\u001b[0;32m---> 24\u001b[0;31m         for doc in new_docs]#review in reviews \n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;31m#print(texts2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "# bag of words\n",
    "new_dictionary = corpora.Dictionary(texts2)# create dictionary object from cleaned texts\n",
    "new_dictionary.save('/tmp/tamalpais_pediatrics.dict') # store the dictionary, for future reference\n",
    "print(new_dictionary)\n",
    "#print(new_dictionary.token2id)\n",
    "\n",
    "# form new corpus\n",
    "new_corpus = [new_dictionary.doc2bow(text) for text in texts2]\n",
    "# A trained model can used be to transform new, unseen documents \n",
    "# (plain bag-of-words count vectors) into LDA topic distributions:\n",
    "\n",
    "# get topic probability distribution for a new review: TransformedCorpus' object\n",
    "new_doc_lda = lda[new_corpus]\n",
    "#new_doc_lda.print_topics()#doesn't work\n",
    "print(new_doc_lda)#This just prints the object: <gensim.interfaces.TransformedCorpus object at 0x10d3ccf10>\n",
    "# throws away sstats, the second part of the returned tuple\n",
    "gammas,_ = lda.inference(new_corpus)# first element is gammas matrix: topics by documents - gamma (parameters controlling the topic weights) for each document in the chunk\n",
    "# Is normalization needed\n",
    "norm_gammas = gammas/np.sum(gammas,axis=1)\n",
    "print(norm_gammas)\n",
    "\n",
    "# KEY QUESTIONS/To DO\n",
    "# *** How do I see the results applied to my new document???\n",
    "# *** I still don't know what to graph\n",
    "# *** How do I get an example review that is highly \"representative of a given topic?\"\n",
    "# I still don't know the best way to reduce the topic dimensonality space\n",
    "# I don't understand the LDA results, and why stop words are not fully suppressed\n",
    "# Need to remove the access key from my git file for the YELP data API program\n",
    "# Need to pass an argument from webpage to flask, manipulate it and pass it back to output page\n",
    "# Add insight to linked in\n",
    "# Work on resume\n",
    "# Revise the Yelp API program and split into two programs - 1) get businesses, 2) get reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2) Infer topic distributions on new, unseen documents:\n",
    "#doc_lda = lda[mmcorpus]\n",
    "doc_lda = lda[corpus]\n",
    "print(lda.inference(corpus))\n",
    "\n",
    "# 3) Update model with new documents:\n",
    "#lda.update(new_training_corpus)\n",
    "#lda.print_topics(5)\n",
    "\n",
    "# row = [[d[1] for d in doc] for doc in corpus_lsi]\n",
    "# df = pd.DataFrame(row).sort(0,axis=0,ascending=False)#0 sorts on the first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-a4978e50f6dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#shape (10,2) for num_words=5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#lda.print_topics(10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#row = [[d[1] for d in doc] for doc in doc_lda]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'corpus' is not defined"
     ]
    }
   ],
   "source": [
    "print(lda.top_topics(corpus, num_words=5)[:][0])\n",
    "lda.top_topics(corpus, num_words=5)#shape (10,2) for num_words=5\n",
    "#lda.print_topics(10)\n",
    "\n",
    "#row = [[d[1] for d in doc] for doc in doc_lda]\n",
    "#df = pd.DataFrame(row).sort(0,axis=0,ascending=False)#0 sorts on the first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualization\n",
    "\n",
    "vis_data = pyLDAvis.gensim.prepare(lda, corpus, dictionary)\n",
    "pyLDAvis.display(vis_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

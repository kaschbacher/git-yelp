{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# key code I talked about with Melinda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We established that gammas are not the parameter I want to focus on\n",
    "gamm_mat =  lda.inference(corpus)[0]\n",
    "print gamm_mat.shape\n",
    "print np.sum(gamm_mat, 1)[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# corpus is a list of lists.  Each inner list corresponds to one review document. \n",
    "# Within that list are tuples.  Each tuple contains a word id (serialized) and frequency of occurrence. This is a BOW representation.\n",
    "\n",
    "count = 0 \n",
    "for rev_bow in corpus:#loop over bag of words for each review \n",
    "    count += 1\n",
    "    if count > 5:# stop after 5 reviews \n",
    "        break \n",
    "    topic_dist = lda[rev_bow]#obtain the distribution of topics by applying lda model to BOW\n",
    "    print 'topic_dist:', topic_dist# topic dist gives a tuple (17, .989) = topic #17.\n",
    "    \n",
    "    for topic_tuple in topic_dist: \n",
    "        print topic_tuple[0], lda.print_topic(topic_tuple[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"topic_dist: [(17, 0.98949275362317668)]\n",
    "17 0.026*surgery + 0.019*doctor + 0.014*would + 0.013*back + 0.012*pain + 0.012*good + 0.009*see + 0.009*need + 0.009*time + 0.009*go\n",
    "topic_dist: [(1, 0.43799803177416646), (13, 0.34823940076564874), (28, 0.19376256746016118)]\n",
    "1 0.023*surgery + 0.023*pain + 0.020*knee + 0.016*office + 0.013*much + 0.011*time + 0.010*would + 0.009*months + 0.008*really + 0.008*able\n",
    "13 0.024*he's + 0.020*surgery + 0.020*really + 0.016*great + 0.014*get + 0.013*time + 0.012*one + 0.010*office + 0.010*staff + 0.009*like\n",
    "28 0.024*doctor + 0.021*i've + 0.021*time + 0.018*he's + 0.017*seen + 0.015*ever + 0.012*good + 0.010*make + 0.010*never + 0.009*service\n",
    "topic_dist: [(1, 0.99207650272928827)]\n",
    "1 0.023*surgery + 0.023*pain + 0.020*knee + 0.016*office + 0.013*much + 0.011*time + 0.010*would + 0.009*months + 0.008*really + 0.008*able\n",
    "topic_dist: [(6, 0.98333333333303397)]\n",
    "6 0.017*back + 0.015*surgery + 0.012*shoulder + 0.012*injury + 0.011*see + 0.011*even + 0.010*went + 0.010*care + 0.009*issues + 0.008*treatment\n",
    "topic_dist: [(11, 0.96419753086414561)]\n",
    "11 0.063*knee + 0.026*surgery + 0.014*doctor + 0.013*surgeon + 0.011*best + 0.011*could + 0.011*time + 0.010*recommended + 0.009*see + 0.009*went\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WORK OUT HOW TO GET Distribution of topics over reviews - i.e., Rev 1 is 99% topic 28.\n",
    "# Milinda\n",
    "\n",
    "count = 0 \n",
    "for rev_bow in corpus: \n",
    "    count += 1\n",
    "    if count > 3: \n",
    "        break \n",
    "    topic_dist = lda[rev_bow]\n",
    "    print 'topic_dist:', topic_dist#for each review, tells you the main topics associated with that review by topic #, percentage.\n",
    "    \n",
    "    for topic_tuple in topic_dist: \n",
    "        print topic_tuple[0], lda.print_topic(topic_tuple[0]),'\\n'#prints topic # and the words for that topic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

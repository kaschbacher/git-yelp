{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "from gensim import corpora, models, similarities, utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyLDAvis.gensim\n",
    "import pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gensim.models.ldamodel.LdaModel'>\n"
     ]
    }
   ],
   "source": [
    "# f = file('lda.pkl', 'rb')\n",
    "# loaded_obj = pickle.load(f)\n",
    "lda = pickle.load(open('lda.p','rb'))\n",
    "# f.close()\n",
    "print(type(lda))\n",
    "\n",
    "norm_gammas = pickle.load(open('norm_gammas_df.p', 'rb'))#actually np array until I rerun NLP_all_reviews-LDA\n",
    "norm_gammas_df = pd.DataFrame(norm_gammas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'0.010*surgery + 0.006*time + 0.006*see + 0.005*first + 0.005*would + 0.005*really + 0.005*great + 0.004*like + 0.004*could + 0.004*office',\n",
       " u\"0.005*see + 0.005*office + 0.005*time + 0.005*i've + 0.005*would + 0.005*like + 0.004*really + 0.004*staff + 0.004*always + 0.004*going\",\n",
       " u\"0.007*see + 0.006*would + 0.005*office + 0.005*like + 0.004*great + 0.004*never + 0.004*i've + 0.004*got + 0.004*good + 0.003*appointment\",\n",
       " u\"0.008*time + 0.007*office + 0.006*would + 0.006*like + 0.005*see + 0.005*even + 0.004*back + 0.004*didn't + 0.003*i've + 0.003*told\",\n",
       " u\"0.005*i've + 0.005*office + 0.005*would + 0.005*never + 0.005*see + 0.004*time + 0.004*surgery + 0.004*went + 0.004*really + 0.004*first\",\n",
       " u\"0.006*back + 0.006*would + 0.005*time + 0.005*office + 0.005*pain + 0.004*go + 0.004*told + 0.003*didn't + 0.003*like + 0.003*really\",\n",
       " u\"0.008*like + 0.007*office + 0.005*don't + 0.005*would + 0.005*feel + 0.005*really + 0.004*insurance + 0.004*appointment + 0.004*i've + 0.004*even\",\n",
       " u\"0.008*time + 0.006*feel + 0.005*office + 0.005*staff + 0.005*great + 0.005*like + 0.004*see + 0.004*really + 0.004*i've + 0.004*first\",\n",
       " u\"0.006*time + 0.005*like + 0.005*office + 0.005*would + 0.004*great + 0.004*he's + 0.004*first + 0.004*even + 0.004*really + 0.004*i'm\",\n",
       " u\"0.007*would + 0.007*surgery + 0.006*great + 0.005*back + 0.005*office + 0.005*time + 0.005*never + 0.005*like + 0.004*i've + 0.004*see\"]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_doc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-830da301264e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         5 Stars!  Thumbs up!\"\"\"]\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# QUICK FORMAT: remove extra spaces and new lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mnew_document\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_doc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m#print(new_document)#type list, shape: (1,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_doc' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a new corpus & apply LDA model to the new corpus\n",
    "# https://radimrehurek.com/gensim/models/ldamodel.html#id2\n",
    "# https://radimrehurek.com/gensim/wiki.html#latent-dirichlet-allocation\n",
    "\n",
    "new_document = [u\"\"\"We love Tamalpais Pediatrics and our children's doctor, John Lee. Like other reviewers have found, with their doctors, \n",
    "           Dr. Lee is patient, listens and addresses concerns we have about our childrens health.  I don't know if all pediatricians will come to the hospital to meet the new baby, but Dr. Lee has come to see both our daughters after they were born...\n",
    "           We've seen Dr. Branco when Dr. Lee was unavailable and were relieved to see he and Dr. Lee are very similar in bedside manners.  \n",
    "        Crystal Cox, the PA, is also a dream.  Shes warm and very easygoing with our young children.  I've no problems having her see the kids when one of the MD s are not available.\n",
    "        I'm sorry to see Deana S. did not have a good experience with the receptionist, but I have to say that I've never had any problems with any of the staff.  They are all professional and very caring with the children.  \n",
    "        5 Stars!  Thumbs up!\"\"\"]\n",
    "# QUICK FORMAT: remove extra spaces and new lines\n",
    "new_document = [\" \".join(element.replace(\"\\n\",\"\").split()) for element in new_document]\n",
    "#print(new_document)#type list, shape: (1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def canonicalize(word):    \n",
    "    bads = ['dr.',\"n't\",\"'ve\",\"'re\",'wo',\"'m\"]\n",
    "    goods = ['dr','not','have','are','will','am']\n",
    "\n",
    "    try:\n",
    "        idx = bads.index(word)\n",
    "        word=goods[idx]\n",
    "    except ValueError as e:\n",
    "        word=word\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defines the pattern for money and times - used by nltk tokenizer\n",
    "def get_pat_for_tokenizer():\n",
    "    from nltk.tokenize import regexp_tokenize\n",
    "    \"\"\"money and time patterns formatted to fit in nltk RegexpTokenizer object, debugged with s2 below\"\"\"\n",
    "    #s2 = 'it took until 12:30 am to get an appointment and I spent $3.50'\n",
    "    \n",
    "    pat = '\\w+|\\$[\\d\\.]+|\\S+'\n",
    "    pat2 = '\\d+\\:[\\d]+\\s?(pm|am)|\\S+'\n",
    "\n",
    "    final_pattern = '('+pat2+')' +'|'+ '('+pat+')'#must be one string argument... | is OR\n",
    "    return final_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NLTK code\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "tokenizer = RegexpTokenizer(get_pat_for_tokenizer())#time & money\n",
    "\n",
    "# document obj passed to tokenizer must be type str\n",
    "texts = [canonicalize(word) for word in tokenizer.tokenize(str(new_document).lower()) \n",
    "         if word not in stopwords.words()]\n",
    "texts = [texts]#BOW dictionary requires texts obj be converted from type str to list\n",
    "#print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(70 unique tokens: [u'born...\\\\n', u'dream.', u'love', u'addresses', u\"don't\"]...)\n"
     ]
    }
   ],
   "source": [
    "# Store Dictionary\n",
    "new_dictionary = corpora.Dictionary(texts)# create dictionary object from cleaned texts (texts type list obj)\n",
    "new_dictionary.save('tamalpais_pediatrics.dict') # store the dictionary, for future reference\n",
    "print(new_dictionary)\n",
    "#print(new_dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00116306  0.73000002  0.00116308  0.00116308  0.26069543  0.00116304\n",
      "   0.00116311  0.00116298  0.00116313  0.00116309]]\n"
     ]
    }
   ],
   "source": [
    "# FORM new Bag-of-words corpus (count vectors)\n",
    "# A trained LDA model can used be to transform new, unseen documents (formatted as BOW)\n",
    "\n",
    "new_corpus = [new_dictionary.doc2bow(text) for text in texts]#both text and texts are type list\n",
    "\n",
    "# Obtain LDA topic distributions for new BOW corpus:\n",
    "#\n",
    "# get topic probability distribution for a new review\n",
    "# object: <gensim.interfaces.TransformedCorpus object\n",
    "new_doc_lda = lda[new_corpus]\n",
    "#new_doc_lda.print_topics()#doesn't work\n",
    "#print(new_doc_lda)#This just prints the  at 0x10d3ccf10>\n",
    "#print(lda.top_topics(corpus, num_words=5)[:][0])\n",
    "#lda.top_topics(corpus, num_words=5)#shape (10,2) for num_words=5\n",
    "#lda.print_topics(10)\n",
    "\n",
    "# Obtain GAMMAS MATRIX:  topics by documents\n",
    "# gammas =  (parameters controlling the topic weights) for each document\n",
    "# Is normalization needed?\n",
    "# throws away sstats, the second part of the returned tuple\n",
    "# gammas and norm-gammas have shape: (1,10)\n",
    "gammas,_ = lda.inference(new_corpus)# first element is gammas matrix: \n",
    "norm_gammas = gammas/np.sum(gammas,axis=1)[:,None]#sum is shape (1,) - sum of the ten gammas. \n",
    "print(norm_gammas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0\n",
      "2   0.730000\n",
      "5   0.260695\n",
      "9   0.001163\n",
      "7   0.001163\n",
      "10  0.001163\n",
      "4   0.001163\n",
      "3   0.001163\n",
      "1   0.001163\n",
      "6   0.001163\n",
      "8   0.001163\n"
     ]
    }
   ],
   "source": [
    "# PUT GAMMAS IN DATAFRAME, SORTED BY TOPIC IMPORTANCE\n",
    "# Set row indices to match LDA topic numbers instead of being 0-indexed\n",
    "df = pd.DataFrame(norm_gammas.T, index=np.arange(1,11))\n",
    "#print(df)\n",
    "print(df.sort(0,axis=0,ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# KEY QUESTIONS/To DO\n",
    "# *** Still confused about exactly what to graph\n",
    "# *** How do I get an example review that is highly \"representative of a given topic?\"\n",
    "# I still don't know the best way to reduce the topic dimensonality space\n",
    "# Work on resume\n",
    "# Revise the Yelp API program and split into two programs - 1) get businesses, 2) get reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# row = [[d[1] for d in doc] for doc in corpus_lsi]\n",
    "# df = pd.DataFrame(row).sort(0,axis=0,ascending=False)#0 sorts on the first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualization - not working applied to new_corpus\n",
    "\n",
    "# vis_data = pyLDAvis.gensim.prepare(lda, new_corpus, new_dictionary)\n",
    "# pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 0.00571359]]), array([[ 0.00410244]]), array([[ 0.00679289]]))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# 1 = highest cosine similarity, 0 = lowest similarity, -1 = inverse similarity (exact opposites)\n",
    "\n",
    "v1 = norm_gammas_df[0:1]#row 0, type dataframe\n",
    "v2 = norm_gammas_df[10:11]\n",
    "v3 = norm_gammas_df[100:101]\n",
    "\n",
    "\n",
    "#cosine_similarity([1, 0, -1], [-1,-1, 0])\n",
    "#output = array([[-0.5]])\n",
    "\n",
    "cs12 = cosine_similarity(v1, v2)#type numpy array, shape (1,1)\n",
    "cs13 = cosine_similarity(v1, v3)\n",
    "cs23 = cosine_similarity(v2, v3)\n",
    "\n",
    "print(cs12, cs13, cs23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Yelp API v2.0 code sample.\n",
    "This program demonstrates the capability of the Yelp API version 2.0\n",
    "by using the Search API to query for businesses by a search term and location,\n",
    "and the Business API to query additional information about the top result\n",
    "from the search query.\n",
    "Please refer to http://www.yelp.com/developers/documentation for the API documentation.\n",
    "This program requires the Python oauth2 library, which you can install via:\n",
    "`pip install -r requirements.txt`.\n",
    "Sample usage of the program:\n",
    "`python sample.py --term=\"bars\" --location=\"San Francisco, CA\"`\n",
    "This program only works with python 2.7, not 3\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import pprint\n",
    "import sys\n",
    "import urllib\n",
    "import urllib2\n",
    "import oauth2\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import pprint as pp\n",
    "import lxml\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "\n",
    "# Global Variables\n",
    "API_HOST = 'api.yelp.com'\n",
    "DEFAULT_TERM = 'physicians'\n",
    "DEFAULT_LOCATION = 'San Francisco, CA'\n",
    "SEARCH_LIMIT = 20\n",
    "SEARCH_PATH = '/v2/search/'\n",
    "BUSINESS_PATH = '/v2/business/'\n",
    "\n",
    "# OAuth credential placeholders that must be filled in by users.\n",
    "CONSUMER_KEY = ''\n",
    "CONSUMER_SECRET = ''\n",
    "TOKEN = ''\n",
    "TOKEN_SECRET = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def request(host, path, url_params=None):\n",
    "    \"\"\"Prepares OAuth authentication and sends the request to the API.\n",
    "    Args:\n",
    "        host (str): The domain host of the API.\n",
    "        path (str): The path of the API after the domain.\n",
    "        url_params (dict): An optional set of query parameters in the request.\n",
    "    Returns:\n",
    "        dict: The JSON response from the request.\n",
    "    Raises:\n",
    "        urllib2.HTTPError: An error occurs from the HTTP request.\n",
    "    \"\"\"\n",
    "    url_params = url_params or {}\n",
    "    url = 'http://{0}{1}?'.format(host, urllib.quote(path.encode('utf8')))\n",
    "\n",
    "    consumer = oauth2.Consumer(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    oauth_request = oauth2.Request(method=\"GET\", url=url, parameters=url_params)\n",
    "\n",
    "    oauth_request.update(\n",
    "        {\n",
    "            'oauth_nonce': oauth2.generate_nonce(),\n",
    "            'oauth_timestamp': oauth2.generate_timestamp(),\n",
    "            'oauth_token': TOKEN,\n",
    "            'oauth_consumer_key': CONSUMER_KEY\n",
    "        }\n",
    "    )\n",
    "    token = oauth2.Token(TOKEN, TOKEN_SECRET)\n",
    "    oauth_request.sign_request(oauth2.SignatureMethod_HMAC_SHA1(), consumer, token)\n",
    "    signed_url = oauth_request.to_url()\n",
    "    \n",
    "    print (u'Querying {0} ...'.format(url))\n",
    "\n",
    "    conn = urllib2.urlopen(signed_url, None)\n",
    "    try:\n",
    "        response = json.loads(conn.read())\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def search(term, location, limit, offset):\n",
    "    \"\"\"Query the Search API by a search term and location.\n",
    "    Args:\n",
    "        term (str): The search term passed to the API.\n",
    "        location (str): The search location passed to the API.\n",
    "    Returns:\n",
    "        dict: The JSON response from the request.\n",
    "    \"\"\"\n",
    "    \n",
    "    url_params = {\n",
    "        'term': term.replace(' ', '+'),\n",
    "        'location': location.replace(' ', '+'),\n",
    "        'limit': SEARCH_LIMIT,\n",
    "        'offset': offset\n",
    "    }\n",
    "    return request(API_HOST, SEARCH_PATH, url_params=url_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_business(business_id):\n",
    "    \"\"\"Query the Business API by a business ID.\n",
    "    Args:\n",
    "        business_id (str): The ID of the business to query.\n",
    "    Returns:\n",
    "        dict: The JSON response from the request.\n",
    "    \"\"\"\n",
    "    business_path = BUSINESS_PATH + business_id\n",
    "\n",
    "    return request(API_HOST, business_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def query_api(term, location, limit, offset):\n",
    "    \"\"\"Queries the API by the input values from the user.\n",
    "    Args:\n",
    "        term (str): The search term to query.\n",
    "        location (str): The location of the business to query.\n",
    "    \"\"\"\n",
    "    response = search(term, location, limit, offset)\n",
    "#     pprint.pprint(response, indent=2)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_business_from_API(response):\n",
    "    businesses = response.get('businesses')\n",
    "\n",
    "    if not businesses:\n",
    "        print u'No businesses for {0} in {1} found.'.format(term, location)\n",
    "        return\n",
    "    return businesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_html(business_id):\n",
    "    \n",
    "    yelp_url = 'http://www.yelp.com/biz/'+business_id\n",
    "    response = urllib2.urlopen(yelp_url)\n",
    "    html = response.read()\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_myhtml(html_filename, html):\n",
    "    # Save the html file\n",
    "    with open(html_filename, 'wb') as f:\n",
    "        f.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def insert_business_SQL(yelp_id, stars, reviews, city_id):\n",
    "    con = False\n",
    "    try:\n",
    "        con = pymysql.connect(host='localhost', port=3307, user='root', passwd='', db='yelpdata')\n",
    "        with con:\n",
    "            cur = con.cursor()\n",
    "            #print(type(yelp_id), type(stars), type(reviews)\n",
    "            #'1' at the end is for the city id, which for now is just SF\n",
    "            myvalues = \"'\" + yelp_id + \"',\" + str(stars) + \",\" + str(reviews) + \",\" + \"1\"\n",
    "            sql = 'INSERT INTO business(yelp_id,stars,reviews,city_id) VALUES('+myvalues+')'\n",
    "            cur.execute(sql)\n",
    "            #print sql\n",
    "    except pymysql.Error, e:\n",
    "        print \"Error %d: %s\" % (e.args[0],e.args[1])\n",
    "        sys.exit(1)\n",
    "    finally:\n",
    "        if con:\n",
    "            con.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def query_SQL(yelp_business_id):\n",
    "    con = False\n",
    "    rows = []\n",
    "    try:\n",
    "        con = pymysql.connect(host='localhost', port=3307, user='root', passwd='', db='yelpdata')\n",
    "        with con:\n",
    "            cur = con.cursor()\n",
    "            sql = 'USE yelpdata;'\n",
    "            cur.execute(sql)\n",
    "            sql = 'SELECT id FROM business WHERE yelp_id = \"'+yelp_business_id+'\";' \n",
    "            #print(sql)\n",
    "            cur.execute(sql)\n",
    "            rows = cur.fetchall()\n",
    "            #print('business id from table: ',rows, type(rows))\n",
    "    except pymysql.Error, e:\n",
    "        print \"Error %d: %s\" % (e.args[0],e.args[1])\n",
    "        sys.exit(1)\n",
    "    finally:\n",
    "        if con:\n",
    "            con.close()\n",
    "    return rows     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use sqlalchemy & pysql\n",
    "# cmd = 'mysql+pymysql://root@localhost:3307/yelpdata'\n",
    "# engine = create_engine(cmd) #imported from alchemy\n",
    "# df.to_sql('review',engine, if_exists='append', index=False)#ignore df index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_html(string,int):\n",
    "    # accepts a rating or date and returns a float btw 0.0 and 5.0, or date-string\n",
    "    s = str(string)\n",
    "    s = s.lstrip('[<meta content=\"')\n",
    "    if int==0:\n",
    "        s = float(s[0:3])#star ratings are always 3 characters long\n",
    "    elif int==1:\n",
    "        stop = s.find('\"')#date lengths could vary\n",
    "        s = s[0:stop]\n",
    "    else: \n",
    "        print('Wrong integer given to format_rating. Must be 0 for rating or 1 for date: ',int)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# not working i don't know why\n",
    "def remove_backslash(review):\n",
    "    #review = review.replace(u'\\xa0','')\n",
    "    review = review.replace(u\"\\\\\",'')#This doesn't work because in many cases it is a combination of characters with the backslash that represents a one-byte thing??\n",
    "    review = review.replace(u\"/\",'')\n",
    "    review = review.replace(u\"(\",'')\n",
    "    review = review.replace(u\")\",'')\n",
    "    review = review.replace(u\"-\",'')\n",
    "    review = review.replace(u'\"','')\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scrape_reviews(html_filename):\n",
    "\n",
    "    # open the html file/object with beautiful soup\n",
    "    \n",
    "    soup = BeautifulSoup(open(html_filename), \"lxml\")\n",
    "\n",
    "    #pp.pprint(ptext)#<class 'bs4.element.ResultSet'>\n",
    "    ptext = soup.find_all('p', {'itemprop': 'description'})\n",
    "    reviews = [ptext[i].get_text() for i in range(0,len(ptext))]\n",
    "    reviews = [filter(lambda x: x in string.printable, review) for review in reviews]\n",
    "    reviews = [remove_backslash(review) for review in reviews]\n",
    "    \n",
    "#     bads = [u'\\xa0',\"\\\\\"]\n",
    "#     reviews = [[review.replace(bad,'') for review in reviews]\n",
    "#                for bad in bads]\n",
    "    \n",
    "    # Examples of what the html looks like:\n",
    "    # <meta itemprop=\"ratingValue\" content=\"5.0\">\n",
    "    # <meta itemprop=\"datePublished\" content=\"2013-03-27\">\n",
    "\n",
    "    rstars =[];rdates=[]\n",
    "    rstars = [pt.parent.find_all('meta', {'itemprop':'ratingValue'}) for pt in ptext]\n",
    "    rdates = [pt.parent.find_all('meta', {'itemprop':'datePublished'}) for pt in ptext]\n",
    "    rstars =[format_html(rstar,0) for rstar in rstars]\n",
    "    rdates =[format_html(rdate,1) for rdate in rdates]\n",
    "\n",
    "    # There's an overall rating on this page I could also get, but it should match bstars\n",
    "\n",
    "    # Ensure that ratings and reviews are vectors of the same length\n",
    "    if len(rstars)!=len(reviews):\n",
    "        print('Length of rstars and reviews for ',html_filename[24:],' on this page do not match.')\n",
    "        #print('rstars len: ',len(rstars),' reviews len: ',len(reviews))\n",
    "        rmin = min(len(rstars),len(reviews))\n",
    "        rstars = rstars[0,rmin]; reviews = reviews[0,rmin]; rdates = rdates[0,rmin]\n",
    "\n",
    "    #Here I manually verified that the star-ratings, reviews, and dates match up with a few pages\n",
    "#     for i in range(0,len(reviews)):\n",
    "#         print(rstars[i],rdates[i],reviews[i])\n",
    "        \n",
    "    return [rstars], [reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def insert_reviews_SQL(business_id, rstar, review):\n",
    "    con = False\n",
    "    try:\n",
    "        con = pymysql.connect(host='localhost', port=3307, user='root', passwd='', db='yelpdata')\n",
    "        with con:\n",
    "            cur = con.cursor()\n",
    "            #print('inserting into review db')\n",
    "            #print(type(business_id), type(rstar), type(review))\n",
    "            myvalues = \"'\" + str(business_id)+\"',\" + str(rstar) + \",\" + '\"'+review+'\"'\n",
    "            sql = 'INSERT INTO review(business_id,stars,comment) VALUES('+myvalues+')'\n",
    "            #print(sql)\n",
    "            cur.execute(sql)\n",
    "    except pymysql.Error, e:\n",
    "        print \"Error %d: %s\" % (e.args[0],e.args[1])\n",
    "        sys.exit(1)\n",
    "    finally:\n",
    "        if con:\n",
    "            con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying http://api.yelp.com/v2/search/? ...\n",
      "('Loop count: ', 0)\n",
      "Result for business \"jim-savage-md-san-francisco\" found:\n",
      "('business id = ', 303)\n",
      "('Loop count: ', 1)\n",
      "Result for business \"albert-w-chow-m-d-san-francisco\" found:\n",
      "('business id = ', 304)\n",
      "('Loop count: ', 2)\n",
      "Result for business \"steven-h-sloan-md-san-francisco-2\" found:\n",
      "('business id = ', 305)\n",
      "('Loop count: ', 3)\n",
      "Result for business \"evan-r-ransom-md-san-francisco\" found:\n",
      "('business id = ', 306)\n",
      "('Loop count: ', 4)\n",
      "Result for business \"sheena-kong-md-san-francisco-2\" found:\n",
      "('business id = ', 307)\n",
      "('Loop count: ', 5)\n",
      "Result for business \"vail-c-reese-md-and-felicia-hall-md-san-francisco\" found:\n",
      "('business id = ', 308)\n",
      "('Loop count: ', 6)\n",
      "Result for business \"david-n-schindler-md-san-francisco\" found:\n",
      "('business id = ', 309)\n",
      "('Loop count: ', 7)\n",
      "Result for business \"alla-boykoff-md-san-francisco\" found:\n",
      "('business id = ', 310)\n",
      "('Loop count: ', 8)\n",
      "Result for business \"the-well-clinic-san-francisco-3\" found:\n",
      "('business id = ', 311)\n",
      "('Loop count: ', 9)"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "#     parser = argparse.ArgumentParser()\n",
    "\n",
    "#     parser.add_argument('-q', '--term', dest='term', default=DEFAULT_TERM, type=str, help='Search term (default: %(default)s)')\n",
    "#     parser.add_argument('-l', '--location', dest='location', default=DEFAULT_LOCATION, type=str, help='Search location (default: %(default)s)')\n",
    "\n",
    "#     input_values = parser.parse_args()#This throws an error in Jupyter because there is no input to parse\n",
    "\n",
    "    try:\n",
    "        #query_api(input_values.term, input_values.location)\n",
    "        response = query_api(term=DEFAULT_TERM, location=DEFAULT_LOCATION, limit=20, offset=120)\n",
    "    except urllib2.HTTPError as error:\n",
    "        sys.exit('Encountered HTTP error {0}. Abort program.'.format(error.code))\n",
    "    \n",
    "    businesses = get_business_from_API(response)\n",
    "    total_nbusinesses = response.get('total')#number of businesses\n",
    "    #print(total_nbusinesses)\n",
    "    \n",
    "    for i in range(0,20):# loop over 20 businesses on each YELP API query\n",
    "    #for i in range(0,1):# for debugging: loop over 1 business for each YELP API query\n",
    "        print('Loop count: ',i)\n",
    "        yelp_business_id = businesses[i]['id']\n",
    "        bus_rating = businesses[i]['rating']\n",
    "        bus_nreviews = businesses[i]['review_count']#for each business\n",
    "        bus_categories = businesses[i]['categories']#e.g., Family Practice\n",
    "\n",
    "        print u'Result for business \"{0}\" found:'.format(yelp_business_id)\n",
    "        \n",
    "        # Add business info to MySQL table: business (other tables are city and review)\n",
    "        insert_business_SQL(yelp_business_id, bus_rating, bus_nreviews, 1)\n",
    "        business_id = query_SQL(yelp_business_id)#business id is a tuple in a tuple\n",
    "    \n",
    "        print('business id = ',business_id[0][0])\n",
    "\n",
    "        # Save a temporary html file: soup breaks if you pass it html obj\n",
    "        html_filename = yelp_business_id +'.html'\n",
    "        html = get_html(yelp_business_id)#returns an html page\n",
    "        #html_filename = 'temp.html'\n",
    "        #save_myhtml(html_filename, html)\n",
    "\n",
    "        #Get reviews & their stars - Beautiful Soup scrape\n",
    "        rstars,reviews = scrape_reviews(html_filename)\n",
    "\n",
    "        for i in range(0,np.shape(rstars)[1]):#np.shape of rstars is (1,40)\n",
    "        #for i in range(0,1):#np.shape of rstars is (1,40)\n",
    "            #print('SQL review input: ',business_id[0], rstars[0][i],reviews[0][i[:10]])\n",
    "            insert_reviews_SQL(business_id[0][0], rstars[0][i], reviews[0][i])\n",
    "\n",
    "            \n",
    "            #x = np.asarray([[business_id]*40]).T\n",
    "            #df = pd.DataFrame(rstars,reviews)\n",
    "            #print(df)\n",
    "\n",
    "#         DEGUGGING CODE ONLY\n",
    "#         temp_url = 'total-care-plus-san-francisco.html'\n",
    "#         temp_url = 'dan-kalshan-md-san-francisco-2.html'\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "   main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

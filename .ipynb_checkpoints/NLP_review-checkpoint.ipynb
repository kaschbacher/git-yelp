{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import gensim\n",
    "from gensim import corpora, models, similarities\n",
    "from pprint import pprint   # pretty-printer\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# documents is a set of reviews from one doctor's Yelp page\n",
    "# I just copied and pasted in 5 reviews (I think)\n",
    "documents = [u'Dr Yee is amazing. \\xa0I have been seeing her for over 7 years and she delivered my first baby and has been great throughout my entire pregnancy. \\xa0Highly recommend her.', u'Is it inappropriate to review your lady doc? Maybe. But I must give a shootout to my Ob/Gyn soul mate! Dr. Yee is everything that is perfect for me in a doctor. I am a high-strung, anxious individual. This and pregnancy do not mix. Dr. Yee was always so laid back and confident, it rubbed off on me! This is what I need. A confident and cool doc to keep me from thinking I am dying every time some little tiny normal thing goes wrong. She also never pressured me, I told her I didn\\'t want to induce and she said ok, and instead of saying \"you\\'re trying not to get an epidural\" she would say \"you\\'re not getting one\". That confidence and support go a long way! She saw me on time for pretty much every appointment, and I saw her, not another doc, almost every time. Now, Dr. Yee did not deliver my baby. By this, I am still completely devastated. But from my experience, her associates are the nicest women on the planet. Going into labor on a holiday is tough, though. I don\\'t blame or resent her one bit. What she did do, though, was call me right after I had my baby and talked to me for a good 15-20 minutes! Doctors don\\'t do this. They just don\\'t. She asked about the delivery, we laughed, it was the nicest and most caring thing I\\'ve ever witnessed by a healthcare professional. She really cared! So sweet. I want to have another baby, pronto, just so I can keep seeing her! Haha, just kidding! But really, she\\'s the greatest.', u\"Dr. Yee has been my 5 star OBGYN for 8 years!! She is a knowledgeable doctor but over the past years the appointments have become increasingly fast-paced and rushed. When I had a miscarriage she gave me a prescription and said - it would be like a heavier period. Well, I wish. I was in intense labor-pain for 13 hrs, had an allergic reaction and therefore couldn't take any painkillers to deal with the intense pain. When I informed her at the next visit there was no sympathy nor acknowledgment that she had failed to inform me of the side effects or what this was going to be like. I stuck with her after that experience but now I think it's time to find a doc where I feel taken care of and well-informed.\", u'I am a long time patient of Dr. Rebecca Yee, she has seen me through two pregnancies, and she is a perfectly competent and very capable physician. \\xa0It\\'s too bad HER PATIENTS NEVER GET TO SEE HER! \\xa0In the last three years, she has only graced me with her presence once. \\xa0Everytime I\\'ve needed to be seen I was passed down to Olga, (who is very nice BTW) her Physician Assistant. \\xa0Classic case of TOO MANY PATIENTS! When I first began seeing Dr. Yee six years ago, when I was pregnant with my son. I felt like she was a great doctor, who truly cared about her patients and had a personal connection with each of them. I have several friends who all see (or try to see) her. \\xa0I think quite a few of her patients will agree that the personal attention and relationship has certainly changed and given way to rushed appointments in what feels like a factory churnning out patients with a quick \"take two of these and call me in the morning\" . \\xa0Don\\'t even get me started on the front dest/appointment staff. \\xa0I live in Vallejo, CA and I work in Napa. \\xa0I scheduled an 8:30 appointment at Dr. Yee\\'s office (with none other than Olga). \\xa0After getting my two kids up at 6:00am to to take them to daycare by 7 so that I can get on the road to city, I was caught in just a little rush hour morning traffic on interstate eight.y \\xa0I was literally 10 like ONE ZERO minutes late and I was told that I could not been seen. \\xa0Where is the compassion? \\xa0Oh I forgot I was offered a 9:45 appointment and a good luck making it to your job by 10! \\xa0Needless to say, I will be helping Dr. Yee out with her \"too many patients problem\" because now she definately has one less.', u'Dr Yee delivered our first baby and my wife has been a patient of hers throughout the pregnancy. We had a great experience with her. She is a phenomenal doctor, has great bedside manner, and patiently answered our many questions. Sometimes we had to see a nurse practitioner when Dr Yee was not available (or was off delivering babies), but we had no problem getting onto her schedule when we booked a few weeks out. She certainly lived up to her great reviews.']\n",
    "#print(documents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gensim code\n",
    "# remove common words and tokenize\n",
    "common_words = 'for a of the and to in'\n",
    "stoplist = set(common_words.split())\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "        for document in documents]\n",
    "\n",
    "# remove words that appear only once\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:# text is a list of tokenized words from one document/review\n",
    "     for token in text:# token is an individual word\n",
    "         frequency[token] += 1\n",
    "\n",
    "texts = [[token for token in text if frequency[token] > 1]\n",
    "         for text in texts]\n",
    "\n",
    "#print texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NLTK code\n",
    "# remove common words and tokenize\n",
    "common_words = 'for a of the and to in is \\'s by on the to . `` ? _ - / \"\\\"'\n",
    "# add numbers to common words\n",
    "range = np.arange(0,100)\n",
    "ss =''\n",
    "ss = ss.join([' '+str(i) for i in range])\n",
    "\n",
    "stoplist = set(common_words.split())\n",
    "\n",
    "#texts: A list of lists; text: list of tokenized words from 1 doc/review\n",
    "texts = [[word for word in nltk.word_tokenize(document.lower()) if word not in stoplist]\n",
    "        for document in documents]#review in reviews \n",
    "#print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Text canonicalization\n",
    "# s = \"here is a ! sentence&\"\n",
    "# s.find('is')# gives index of starting character for that pattern, else -1\n",
    "for text in texts:\n",
    "    for word in text:\n",
    "        if word=='dr.':\n",
    "            #print(\"found it\")\n",
    "            word=='dr'\n",
    "#print(texts)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(352 unique tokens: [u'all', u'6:00am', u'go', u'certainly', u'answered']...)\n",
      "{u'all': 219, u'6:00am': 223, u'go': 25, u'certainly': 226, u'answered': 341, u'must': 35, u'appointment': 38, u'very': 235, u'induce': 41, u'every': 43, u'cool': 50, u'entire': 17, u'did': 51, u'graced': 245, u'anxious': 54, u'quick': 251, u'talked': 93, u'pregnancies': 256, u'past': 169, u'zero': 313, u'even': 260, u\"n't\": 62, u'what': 63, u'witnessed': 156, u'goes': 72, u'dr.': 73, u'nurse': 347, u'ever': 74, u'told': 75, u'never': 77, u'delivering': 339, u'miscarriage': 197, u'great': 18, u'kids': 269, u'changed': 273, u'appointments': 195, u'experience': 85, u'highly': 15, u'confidence': 79, u'from': 99, u'would': 100, u'visit': 181, u'two': 285, u'next': 183, u'few': 286, u'live': 287, u'call': 107, u'therefore': 186, u'recommend': 12, u'taken': 187, u'ob/gyn': 111, u'started': 293, u'haha': 113, u'baby': 14, u'women': 118, u'me': 119, u'none': 237, u'hour': 299, u'this': 121, u'oh': 271, u'soul': 122, u'reviews': 340, u'can': 126, u'making': 307, u'my': 21, u'give': 129, u'want': 137, u'painkillers': 175, u'!': 140, u'six': 316, u'compassion': 317, u'amazing': 10, u'instead': 146, u'after': 149, u'wrong': 151, u'truly': 238, u'daycare': 328, u'maybe': 155, u'inform': 213, u'so': 158, u'healthcare': 160, u'obgyn': 218, u'office': 220, u'over': 1, u'years': 3, u'through': 224, u'still': 26, u'perfect': 27, u'personal': 227, u',': 31, u'labor': 32, u'late': 229, u'labor-pain': 177, u'weeks': 349, u'holiday': 120, u'them': 233, u'good': 37, u'devastated': 40, u'high-strung': 44, u'they': 45, u'front': 241, u'now': 48, u'nor': 200, u'pregnant': 243, u'always': 52, u'fast-paced': 207, u'each': 250, u'side': 217, u'luck': 252, u'needless': 255, u'epidural': 58, u'forgot': 258, u'our': 346, u'really': 61, u'try': 248, u'acknowledgment': 176, u'factory': 262, u'laid': 70, u'mate': 71, u'7': 11, u'given': 282, u'quite': 266, u'completely': 81, u'care': 201, u'could': 209, u'keep': 86, u'thing': 87, u'onto': 348, u'think': 212, u'first': 22, u'feel': 168, u'one': 92, u'sympathy': 170, u'another': 95, u'city': 281, u'little': 98, u'caught': 284, u'needed': 325, u'too': 288, u'passed': 291, u'time': 109, u'perfectly': 290, u'relationship': 292, u'that': 143, u'doctors': 116, u'off': 153, u'than': 295, u'10': 234, u'13': 203, u'patients': 304, u'8:30': 309, u'say': 135, u'manner': 343, u'have': 4, u'need': 138, u'seen': 312, u'saw': 139, u'any': 193, u'also': 144, u'dest/appointment': 318, u'take': 173, u'laughed': 145, u'pain': 192, u'though': 148, u'who': 322, u'most': 150, u'doc': 127, u'sometimes': 350, u'professional': 162, u'saying': 23, u'bedside': 342, u'find': 174, u'staff': 225, u'(': 228, u'hrs': 182, u'failed': 184, u'only': 230, u'going': 33, u'pretty': 34, u'8': 188, u'interstate': 231, u'do': 36, u'get': 39, u'assistant': 236, u'resent': 42, u'feels': 239, u'dr': 16, u'morning': 247, u'bad': 249, u'she': 20, u'where': 216, u'btw': 253, u'see': 257, u'individual': 59, u'are': 60, u'said': 64, u'pressured': 65, u'inappropriate': 66, u'review': 67, u'available': 331, u'we': 76, u'attention': 265, u'deliver': 78, u'blame': 80, u'job': 267, u'competent': 268, u'reaction': 202, u'prescription': 205, u'many': 306, u'pronto': 112, u'connection': 274, u'churnning': 275, u'tough': 89, u'sweet': 90, u'ca': 278, u'period': 167, u'hers': 345, u'pregnancy': 5, u'throughout': 6, u'patiently': 351, u'caring': 97, u'capable': 283, u'informed': 172, u'three': 305, u'been': 9, u'cared': 104, u'confident': 105, u'much': 106, u'napa': 289, u'lived': 333, u'offered': 294, u'last': 270, u'case': 296, u'physician': 297, u'vallejo': 298, u'heavier': 189, u'these': 300, u'will': 303, u'olga': 272, u'almost': 130, u'it': 132, u'doctor': 142, u')': 314, u'began': 315, u'babies': 335, u'several': 320, u'practitioner': 334, u'definately': 263, u'9:45': 327, u'dying': 154, u'i': 19, u'well': 211, u'asked': 157, u'greatest': 159, u'effects': 196, u'just': 24, u'less': 221, u'increasingly': 164, u'knowledgeable': 165, u'yee': 2, u'not': 46, u'questions': 344, u'mix': 28, u'thinking': 29, u'rebecca': 242, u'had': 30, u'has': 13, u'gave': 190, u'scheduled': 232, u'traffic': 240, u'bit': 47, u'lady': 49, u'like': 206, u'eight.y': 244, u'everytime': 246, u\"'ve\": 53, u'become': 214, u'right': 55, u'deal': 163, u'some': 56, u'back': 57, u'delivered': 7, u'phenomenal': 337, u'normal': 68, u'everything': 69, u'be': 191, u'patient': 264, u'schedule': 336, u'well-informed': 198, u'intense': 199, u'about': 82, u'ok': 83, u'getting': 84, u'or': 88, u'road': 276, u'seeing': 0, u'presence': 277, u'into': 91, u'son': 279, u'down': 280, u'because': 254, u'tiny': 102, u'your': 96, u'her': 8, u'rushed': 178, u'support': 101, u'there': 180, u'long': 94, u'kidding': 103, u'stuck': 166, u'way': 108, u'was': 110, u'allergic': 215, u'but': 114, u'delivery': 115, u'trying': 117, u'with': 179, u'rush': 329, u'wish': 208, u'up': 302, u'planet': 123, u\"'re\": 124, u'nicest': 125, u'problem': 308, u'minutes': 128, u'agree': 310, u'classic': 311, u'am': 131, u'an': 133, u\"''\": 134, u'associates': 136, u'at': 171, u'work': 301, u'rubbed': 141, u'no': 204, u'when': 210, u'other': 319, u'5': 185, u'you': 147, u'out': 259, u'nice': 321, u'star': 194, u'felt': 222, u'helping': 323, u'friends': 324, u'ago': 326, u'booked': 332, u'shootout': 152, u'wife': 338, u'literally': 261, u'15-20': 161, u'once': 330}\n"
     ]
    }
   ],
   "source": [
    "# BAG OF WORDS\n",
    "dictionary = corpora.Dictionary(texts)# create dictionary object from cleaned texts\n",
    "dictionary.save('/tmp/doctor.dict') # store the dictionary, for future reference\n",
    "print(dictionary)\n",
    "#print(type(dictionary))#<class 'gensim.corpora.dictionary.Dictionary'>\n",
    "print(dictionary.token2id)\n",
    "\n",
    "# To merge with another dictionary -  Dictionary.merge_with())# Apply bag of words to reviews & print tokenized dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SERIALIZE & SAVE TO DISK \n",
    "\n",
    "# Convert tokenized documents to sparse vectors: -- [(0, 1), (4, 3),...\n",
    "# new_vec = dictionary.doc2bow(documents[1].lower().split())\n",
    "# print(new_vec)\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "corpora.MmCorpus.serialize('/tmp/doctor.mm', corpus) # store to disk, for later use\n",
    "\n",
    "#print(corpus)\n",
    "# looks like - [[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)... (35, 2)...\n",
    "# word order index -frequency of occurence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tf-idf model\n",
    "# term frequency - inverse document frequency\n",
    "# higher index - occured a lot in a few docs:  log(D/d) ---  uniqueness/singularity\n",
    "# D = # of doc, d = # of doc that that word appears in\n",
    "# tf-idf will convert any vector from bag-of-words integer counts to Tfidf real-valued weights\n",
    "\n",
    "# CAUTION - The same vector space (= the same set of feature ids) must be used for training as well as for subsequent vector transformations. Failure to use the same input feature space, such as applying a different string preprocessing, using different feature ids, or using bag-of-words input vectors where TfIdf vectors are expected, will result in feature mismatch during transformation calls and consequently in either garbage output and/or runtime exceptions.\n",
    "\n",
    "tfidf = models.TfidfModel(corpus) # step 1 -- initialize a model\n",
    "\n",
    "#  Apply tfidf to the whole corpus\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "# for doc in corpus_tfidf:\n",
    "#     print(doc)\n",
    "\n",
    "\n",
    "# example transformation\n",
    "# doc_bow = [(0,1),(1,3)]\n",
    "# print(tfidf[doc_bow]); print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2\n",
      "3  0.619779  0.232931 -0.260150\n",
      "1  0.549346  0.357718 -0.317442\n",
      "2  0.531328  0.314275  0.698156\n",
      "4  0.466477 -0.567117 -0.349622\n",
      "0  0.357273 -0.681029  0.357603\n"
     ]
    }
   ],
   "source": [
    "# Transformations can also be serialized, one on top of another, in a sort of chain:\n",
    "# LSI is another transformation, which acts on the Tf-idf-weighted space\n",
    "\n",
    "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=3)\n",
    "corpus_lsi = lsi[corpus_tfidf]\n",
    "lsi.print_topics(3)\n",
    "\n",
    "# Interpret my Reviews - I have only five docs (reviews) total\n",
    "# The first five reviews all relate moderately to the first topic\n",
    "# Reviews 2-4 relate to a second topic\n",
    "# Review 2 relates to a third topic\n",
    "\n",
    "# Old comment from gensim_tut1\n",
    "# As expected, the first five documents are more strongly related to the second topic \n",
    "# while the remaining four documents to the first topic:\n",
    "\n",
    "# both bow->tfidf and tfidf->lsi transformations are actually executed here, on the fly\n",
    "# for doc in corpus_lsi: \n",
    "#     print(doc)\n",
    "\n",
    "# sort documents on topic assignments\n",
    "# numpy isn't the right structure for sorting based on the first column - dataframe\n",
    "row = [[d[1] for d in doc] for doc in corpus_lsi]\n",
    "\n",
    "# array = np.asarray(row).reshape(5,3)\n",
    "df = pd.DataFrame(row).sort(0,axis=0,ascending=False)#0 sorts on the first column\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'0.197*\"i\" + 0.180*\"patients\" + 0.152*\",\" + 0.148*\"we\" + 0.135*\"me\" + 0.127*\"dr\" + 0.126*\"!\" + 0.116*\"our\" + 0.115*\"do\" + 0.111*\"like\"',\n",
       " u'-0.253*\"entire\" + -0.253*\"amazing\" + -0.253*\"recommend\" + -0.253*\"highly\" + -0.243*\"dr\" + -0.193*\"throughout\" + -0.193*\"delivered\" + -0.184*\"we\" + -0.173*\"our\" + -0.158*\"great\"',\n",
       " u'0.200*\"intense\" + -0.157*\"we\" + 0.157*\"entire\" + 0.157*\"amazing\" + 0.157*\"recommend\" + 0.157*\"highly\" + 0.146*\"over\" + -0.126*\"our\" + -0.109*\"patients\" + 0.101*\"years\"']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi.print_topics()\n",
    "# retrain model with more data\n",
    "# sort documents based on topic assignments\n",
    "# e.g., look at the top five documents assigned to this topic to get a sense what it's about\n",
    "# you train model on many doctors' reviews, but when you do the prediction, you can project\n",
    "# back onto a single doctor\n",
    "# each review might contain a weightings of topics - 70%(T1)+30%(T2)\n",
    "# give each new doctor a star rating per topic - that's the readout - personalized report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
